{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MOT17-02-SDP', 'MOT17-11-SDP', 'MOT17-04-SDP', 'MOT17-05-SDP', 'MOT17-09-DPM', 'MOT17-11-FRCNN', 'MOT17-10-DPM', 'MOT17-10-FRCNN', 'MOT17-09-SDP', 'MOT17-10-SDP', 'MOT17-11-DPM', 'MOT17-13-SDP', 'MOT17-02-DPM', 'MOT17-13-FRCNN', 'MOT17-02-FRCNN', 'MOT17-13-DPM', 'MOT17-04-DPM', 'MOT17-05-FRCNN', 'MOT17-09-FRCNN', 'MOT17-04-FRCNN', 'MOT17-05-DPM']\n"
     ]
    }
   ],
   "source": [
    "mot_dir = \"/home/viplab/Research_DK/Mamba-MOT/GMTracker/data/MOT17/train\"\n",
    "print(os.listdir(mot_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 4)\n",
      "token shape is :  (50, 4)\n",
      "tensor([[  24.1696, -169.7643,  -31.0384, -140.6744],\n",
      "        [  24.2250, -168.5311,  -31.2891, -139.2662],\n",
      "        [  24.4735, -167.7699,  -32.1121, -137.7101],\n",
      "        [  24.4917, -166.2511,  -32.1221, -136.0990],\n",
      "        [  24.7402, -165.4900,  -32.9450, -134.5429],\n",
      "        [  24.7583, -163.9712,  -32.9550, -132.9318],\n",
      "        [  17.9957, -154.1150,  -28.2181, -129.1891],\n",
      "        [  10.7695, -143.6055,  -22.8597, -125.3264],\n",
      "        [   4.0069, -133.7493,  -18.1228, -121.5836],\n",
      "        [  -3.2194, -123.2399,  -12.7644, -117.7209],\n",
      "        [  -2.3353, -121.1249,  -13.1989, -115.0316],\n",
      "        [  -2.2617, -118.3729,  -13.4596, -112.0122],\n",
      "        [  -2.1881, -115.6209,  -13.7203, -108.9930],\n",
      "        [  -2.1145, -112.8689,  -13.9809, -105.9737],\n",
      "        [   8.1498, -121.3947,  -22.0345, -104.4235],\n",
      "        [  19.1873, -130.2720,  -30.0213, -103.0003],\n",
      "        [  29.8779, -139.1653,  -38.4557, -101.3673],\n",
      "        [  40.6822, -148.1471,  -46.6340,  -99.8791],\n",
      "        [  42.7789, -148.8370,  -47.2925,  -99.2724],\n",
      "        [  44.7247, -149.1528,  -47.9665,  -98.3180],\n",
      "        [  46.2442, -149.1011,  -48.2596,  -97.4464],\n",
      "        [  48.5368, -149.4009,  -48.4860,  -96.7020],\n",
      "        [  45.6160, -144.5451,  -45.4139,  -95.1853],\n",
      "        [  42.6952, -139.6893,  -42.3418,  -93.6686],\n",
      "        [  39.6234, -134.4595,  -39.2851,  -91.8044],\n",
      "        [  32.9956, -123.7537,  -35.6271,  -86.3607],\n",
      "        [  26.4815, -113.1363,  -31.7132,  -81.0618],\n",
      "        [  20.2006, -102.4144,  -27.6076,  -75.8281],\n",
      "        [  13.6865,  -91.7970,  -23.6937,  -70.5292],\n",
      "        [   7.4056,  -81.0750,  -19.5881,  -65.2954],\n",
      "        [   1.3178,  -70.8252,  -16.0549,  -59.9137],\n",
      "        [   8.0343,  -73.2624,  -18.4113,  -58.0107],\n",
      "        [  14.9466,  -75.3094,  -20.3355,  -55.9699],\n",
      "        [  21.5121,  -77.3726,  -22.7073,  -53.7192],\n",
      "        [  28.5754,  -79.7937,  -24.6162,  -52.0260],\n",
      "        [  35.1409,  -81.8569,  -26.9879,  -49.7753],\n",
      "        [  41.8200,  -84.0085,  -29.1037,  -47.6695],\n",
      "        [  43.5727,  -83.8522,  -29.2053,  -46.8630],\n",
      "        [  45.4390,  -83.7844,  -29.0509,  -46.2013],\n",
      "        [  47.6180,  -83.9957,  -29.5333,  -45.3121],\n",
      "        [  49.4843,  -83.9279,  -29.3789,  -44.6504],\n",
      "        [  51.2370,  -83.7717,  -29.4805,  -43.8439],\n",
      "        [  53.5296,  -84.0714,  -29.7068,  -43.0995],\n",
      "        [  46.7823,  -73.5586,  -25.9844,  -37.7355],\n",
      "        [  40.0350,  -63.0457,  -22.2620,  -32.3716],\n",
      "        [  33.1367,  -52.1589,  -18.5550,  -26.6600],\n",
      "        [  26.3893,  -41.6460,  -14.8325,  -21.2960],\n",
      "        [  20.4151,  -31.4846,  -11.0433,  -16.0592],\n",
      "        [  13.0906,  -20.2302,   -6.9555,  -10.4304],\n",
      "        [   6.7695,  -10.0849,   -3.6138,   -4.9836]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      " shape of embedded tensot  :  torch.Size([50, 4])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_tracklet(gt_in, object_id):\n",
    "    \"\"\"\n",
    "    Extract the tracklet for a given object ID.\n",
    "    :param df: DataFrame containing the ground truth data.\n",
    "    :param object_id: The ID of the object to extract the tracklet for.\n",
    "    :return: DataFrame containing the tracklet.\n",
    "    \"\"\"\n",
    "    tracklet  = []\n",
    "    # tracklet.append(i) [for i in gt_in if gt_in[i] == object_id]\n",
    "    for i in gt_in:\n",
    "        # print(i)\n",
    "        if i[1] == object_id:\n",
    "            tracklet.append(i[2:6])\n",
    "    return np.array(tracklet)\n",
    "\n",
    "def tokenizer_frames(tracking, sliding_window):\n",
    "    \n",
    "    token  = [] \n",
    "    for i in range(sliding_window):\n",
    "        current_bbox = tracking[i]\n",
    "        # print(\"bounding box at {} frame : {}\".format(i,current_bbox))\n",
    "        # print(\"tracklet at Nth place is : \", tracking[sliding_window])\n",
    "        delta = np.subtract(tracking[sliding_window], current_bbox)\n",
    "        # print(\"delta is : \", delta)\n",
    "        token.append(delta)\n",
    "    \n",
    "    return np.array(token)\n",
    "\n",
    "\n",
    "for sequence in os.listdir(mot_dir):\n",
    "    # seq = os.path.join(mot_dir, sequence)\n",
    "    image_dir = os.path.join(mot_dir, sequence, \"img1\")\n",
    "    gt_file = os.path.join(mot_dir, sequence, \"gt\", \"gt.txt\")\n",
    "    # print(gt_file)\n",
    "\n",
    "    gt_in = np.loadtxt(gt_file, delimiter = \",\")\n",
    "\n",
    "    # print(gt_in)\n",
    "\n",
    "    ## Lets define 1 tracklet first\n",
    "    object_id = 2 ## Tracklet with Object ID = 1\n",
    "    tracklet = get_tracklet(gt_in, object_id)\n",
    "    # print(\" tracklet is : \", gt_in[tracklet])\n",
    "    print(tracklet.shape)\n",
    "\n",
    "    sliding_window = 50\n",
    "    token = tokenizer_frames(tracklet, sliding_window)\n",
    "\n",
    "\n",
    "    print(\"token shape is : \", token.shape)\n",
    "    token = torch.tensor(token, dtype = torch.float32)\n",
    "\n",
    "    input_dim = 4\n",
    "    output_dim = 4\n",
    "    embedding_layer = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    embedded_tensor = embedding_layer(token)\n",
    "\n",
    "    print(embedded_tensor)\n",
    "\n",
    "    print(\" shape of embedded tensot  : \", embedded_tensor.shape)\n",
    "    \n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from mamba_ssm import Mamba\n",
    "\n",
    "class BiMambaEncoder(nn.Module):\n",
    "    def __init__(self, d_model, n_state):\n",
    "        super(BiMambaEncoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.mamba = Mamba(d_model, n_state)\n",
    "\n",
    "        # Norm and feed-forward network layer\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_model * 4, d_model)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Residual connection of the original input\n",
    "        residual = x\n",
    "        \n",
    "        # Forward Mamba\n",
    "        x_norm = self.norm1(x)\n",
    "        mamba_out_forward = self.mamba(x_norm)\n",
    "\n",
    "        # Backward Mamba\n",
    "        x_flip = torch.flip(x_norm, dims=[1])  # Flip Sequence\n",
    "        mamba_out_backward = self.mamba(x_flip)\n",
    "        mamba_out_backward = torch.flip(mamba_out_backward, dims=[1])  # Flip back\n",
    "\n",
    "        # Combining forward and backward\n",
    "        mamba_out = mamba_out_forward + mamba_out_backward\n",
    "        \n",
    "        mamba_out = self.norm2(mamba_out)\n",
    "        ff_out = self.feed_forward(mamba_out)\n",
    "\n",
    "        output = ff_out + residual\n",
    "        return output\n",
    "\n",
    "# Initialize and test the model\n",
    "d_model = 4\n",
    "n_state = 64\n",
    "model = BiMambaEncoder(d_model, n_state).cuda()\n",
    "x = torch.rand(1, 50, d_model).cuda()  # Analog input data: (batch_size, seq_len, feature_dim)\n",
    "output = model(x)\n",
    "print(output.shape)  # Mamba Out: (32, 100, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Tracklets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_tracklets(data):\n",
    "    first_frame = int(np.min(data[:, 0]))\n",
    "    first_frame_data = data[data[:, 0] == first_frame]\n",
    "    # print(\" first frame data : \", first_frame_data)\n",
    "\n",
    "    tracklets = {}\n",
    "    for row in first_frame_data:\n",
    "        # print(\" row is :\", row)\n",
    "        object_id = int(row[1])\n",
    "        if object_id not in tracklets:\n",
    "            tracklets[object_id] = [row[2:6]]\n",
    "    return tracklets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update tracklets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_tracklets_for_frame(data, tracklets, frame):\n",
    "    # unique_frames = np.unique(data[:, 0])\n",
    "\n",
    "\n",
    "    # for frame in unique_frames:\n",
    "    #     if frame == np.min(data[:, 0]):\n",
    "    #         continue\n",
    "    \n",
    "\n",
    "\n",
    "    frame_data = data[data[:, 0] == frame]\n",
    "\n",
    "    for row in frame_data:\n",
    "        object_id = int(row[1])\n",
    "        if object_id in tracklets:\n",
    "            tracklets[object_id].append(row[2:6])\n",
    "        else:\n",
    "            ## Initialize a new tracklet if the object ID does not exist\n",
    "            tracklets[object_id] = [row[2:6]]\n",
    "\n",
    "    return tracklets\n",
    "### Convert tracklet to numpy arrays\n",
    "\n",
    "def convert_tracklets_to_numpy(tracklets):\n",
    "    for object_id , tracklet_data in tracklets.items():\n",
    "        tracklets[object_id] = np.array(tracklet_data)\n",
    "    \n",
    "    return tracklets\n",
    "\n",
    "\n",
    "\n",
    "def load_data(filename):\n",
    "    data = np.loadtxt(filename, delimiter=',', dtype=float)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/home/viplab/Research_DK/Mamba-MOT/GMTracker/data/MOT17/train/MOT17-02-SDP/gt/gt.txt\"\n",
    "data = load_data(filename)\n",
    "tracklets = initialize_tracklets(data)\n",
    "\n",
    "unique_frames = np.unique(data[:, 0])\n",
    "for frame in unique_frames:\n",
    "    if frame == 1:\n",
    "        continue\n",
    "    else:\n",
    "        tracklets = update_tracklets_for_frame(data, tracklets, frame)\n",
    "    # trackletsupdate_tracklets(data, tracklets) ## Updates all the tracklets at once. Can be changed to sending data per frame and updating the tracklets in a better way\n",
    "tracklets = convert_tracklets_to_numpy(tracklets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracklets.get(1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracklet Delta - Creating a Tokenizer function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 4)\n"
     ]
    }
   ],
   "source": [
    "def compute_deltas(tracklet_data):\n",
    "    # Compute deltas as described\n",
    "    deltas = []\n",
    "    for i in range(len(tracklet_data) - 1):\n",
    "        delta = tracklet_data[i+1] - tracklet_data[i]\n",
    "        deltas.append(delta)\n",
    "    return np.array(deltas)\n",
    "\n",
    "\n",
    "# Example tracklet data: shape (num_frames, 4) with columns [cx, cy, w, h]\n",
    "# tracklet_data = np.array([\n",
    "#     [100, 150, 50, 60],\n",
    "#     [105, 155, 50, 60],\n",
    "#     [110, 160, 50, 60]\n",
    "# ])\n",
    "\n",
    "\n",
    "# Create delta values for input sequence\n",
    "\n",
    "window_size = 50\n",
    "tracklet_data = tracklets.get(3)[:window_size+1]\n",
    "\n",
    "tracklet_deltas = compute_deltas(tracklet_data)\n",
    "print(tracklet_deltas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class TemporalTokenEmbedding(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim):\n",
    "        super(TemporalTokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, embedding_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)\n",
    "\n",
    "# Parameters\n",
    "input_dim = tracklet_deltas.shape[1]  # Number of features in deltas (e.g., 4)\n",
    "print(input_dim)\n",
    "# Create and apply embedding layer\n",
    "# embedding_layer = TemporalTokenEmbedding(input_dim, embedding_dim)\n",
    "tracklet_delta_tensor = torch.tensor(tracklet_deltas, dtype=torch.float32).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to implement Bi-Mamba Encdoding Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Forward and Backward Mamba Modules: \n",
    "Implement the forward and backward Mamba modules.\n",
    "#### Create a Bi-Mamba Block: \n",
    "Use the forward and backward modules to process input and apply normalization and MLP.\n",
    "#### Assemble the Bi-Mamba Encoding Layer: \n",
    "Stack multiple Bi-Mamba blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from mamba_ssm import Mamba\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BiMambaBlock(nn.Module):\n",
    "    def __init__(self, d_model, n_state):\n",
    "        super(BiMambaBlock, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.mamba = Mamba(d_model, n_state)\n",
    "\n",
    "        # Norm and feed-forward network layer\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_model * 4, d_model)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Residual connection of the original input\n",
    "        residual = x\n",
    "        \n",
    "        # Forward Mamba\n",
    "        x_norm = self.norm1(x)\n",
    "        mamba_out_forward = self.mamba(x_norm)\n",
    "\n",
    "        # Backward Mamba\n",
    "        x_flip = torch.flip(x_norm, dims=[1])  # Flip Sequence\n",
    "        mamba_out_backward = self.mamba(x_flip)\n",
    "        mamba_out_backward = torch.flip(mamba_out_backward, dims=[1])  # Flip back\n",
    "        print(\"mamba out backward shape :\", mamba_out_backward.shape)\n",
    "    \n",
    "        # Combining forward and backward\n",
    "        mamba_out = mamba_out_forward + mamba_out_backward\n",
    "        mamba_out1  = self.norm2(mamba_out)\n",
    "        print(\"mamba out 1 shape :\", mamba_out1.shape)\n",
    "    \n",
    "        mamba_out2 = self.feed_forward(mamba_out)\n",
    "\n",
    "        ff_out  = mamba_out1 + mamba_out2\n",
    "        # output = ff_out + residual\n",
    "        return ff_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiMambaEncodingLayer(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_blocks):\n",
    "        super(BiMambaEncodingLayer, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_blocks = num_blocks\n",
    "        # self.blocks = nn.ModuleList([BiMambaBlock(input_dim, embedding_dim) for _ in range(num_blocks)])\n",
    "    \n",
    "        self.mamba_block = BiMambaBlock(embedding_dim, embedding_dim)\n",
    "    def forward(self, x):\n",
    "        # print(\" embedding dimension is : \", self.embedding_dim)\n",
    "        # for block in self.blocks:\n",
    "        x = self.mamba_block(x)\n",
    "        # x = self.mamba_block(x)\n",
    "        # x = self.mamba_block(x)\n",
    "        \n",
    "            # x = block(x)\n",
    "            # print(\" x shape in mamba block is : \", x.shape)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x shape is :  torch.Size([50, 128])\n",
      " type of x is :  <class 'torch.Tensor'>\n",
      " x after reshaping it is :  torch.Size([1, 50, 128])\n",
      "mamba out backward shape : torch.Size([1, 50, 128])\n",
      "mamba out 1 shape : torch.Size([1, 50, 128])\n",
      " x shape after  bimamba encoding layer is :  torch.Size([1, 50, 128])\n",
      " x shape after  prediction head layer :  torch.Size([1, 50, 4])\n",
      " shape of predictions :  torch.Size([1, 50, 4])\n"
     ]
    }
   ],
   "source": [
    "class FullModel(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, num_blocks, prediction_dim):\n",
    "        super(FullModel, self).__init__()\n",
    "        self.temporal_token_embedding = TemporalTokenEmbedding(input_dim, embedding_dim)\n",
    "        self.bi_mamba_encoding_layer = BiMambaEncodingLayer(embedding_dim, num_blocks)\n",
    "        self.prediction_head = nn.Linear(embedding_dim, prediction_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.temporal_token_embedding(x)\n",
    "        print(\" x shape is : \", x.shape)\n",
    "        print(' type of x is : ', type(x))\n",
    "        x  =  x.unsqueeze(0)\n",
    "        print(\" x after reshaping it is : \", x.shape)\n",
    "        x = self.bi_mamba_encoding_layer(x)\n",
    "        print(\" x shape after  bimamba encoding layer is : \", x.shape)\n",
    "        x = self.prediction_head(x)\n",
    "        print(\" x shape after  prediction head layer : \", x.shape)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "input_dim = tracklet_delta_tensor.shape[1]  # Number of features in deltas (e.g., 4)\n",
    "embedding_dim = 128 # Example embedding dimension\n",
    "num_blocks = 4  # Number of Bi-Mamba blocks\n",
    "prediction_dim = 4  # Number of predicted offsets\n",
    "\n",
    "# Create and apply model\n",
    "model = FullModel(input_dim, embedding_dim, num_blocks, prediction_dim).cuda()\n",
    "predictions = model(tracklet_delta_tensor).cuda()\n",
    "print(\" shape of predictions : \", predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mamba_fetrack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
