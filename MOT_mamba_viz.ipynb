{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MOT17-11-FRCNN', 'MOT17-02-SDP', 'MOT17-04-FRCNN', 'MOT17-13-DPM', 'MOT17-04-SDP', 'MOT17-09-FRCNN', 'MOT17-02-FRCNN', 'MOT17-04-DPM', 'MOT17-11-DPM', 'MOT17-05-SDP', 'MOT17-11-SDP', 'MOT17-05-FRCNN', 'MOT17-05-DPM', 'MOT17-10-DPM', 'MOT17-13-FRCNN', 'MOT17-09-DPM', 'MOT17-02-DPM', 'MOT17-10-FRCNN', 'MOT17-09-SDP', 'MOT17-13-SDP', 'MOT17-10-SDP']\n"
     ]
    }
   ],
   "source": [
    "mot_dir = \"MOT17/train\"\n",
    "print(os.listdir(mot_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 4)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 50 is out of bounds for axis 0 with size 13",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(tracklet\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     46\u001b[0m sliding_window \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[0;32m---> 47\u001b[0m token \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer_frames\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtracklet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msliding_window\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken shape is : \u001b[39m\u001b[38;5;124m\"\u001b[39m, token\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     51\u001b[0m token \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(token, dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "Cell \u001b[0;32mIn[4], line 23\u001b[0m, in \u001b[0;36mtokenizer_frames\u001b[0;34m(tracking, sliding_window)\u001b[0m\n\u001b[1;32m     20\u001b[0m current_bbox \u001b[38;5;241m=\u001b[39m tracking[i]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# print(\"bounding box at {} frame : {}\".format(i,current_bbox))\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# print(\"tracklet at Nth place is : \", tracking[sliding_window])\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m delta \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msubtract(\u001b[43mtracking\u001b[49m\u001b[43m[\u001b[49m\u001b[43msliding_window\u001b[49m\u001b[43m]\u001b[49m, current_bbox)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# print(\"delta is : \", delta)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m token\u001b[38;5;241m.\u001b[39mappend(delta)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 50 is out of bounds for axis 0 with size 13"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_tracklet(gt_in, object_id):\n",
    "    \"\"\"\n",
    "    Extract the tracklet for a given object ID.\n",
    "    :param df: DataFrame containing the ground truth data.\n",
    "    :param object_id: The ID of the object to extract the tracklet for.\n",
    "    :return: DataFrame containing the tracklet.\n",
    "    \"\"\"\n",
    "    tracklet  = []\n",
    "    # tracklet.append(i) [for i in gt_in if gt_in[i] == object_id]\n",
    "    for i in gt_in:\n",
    "        # print(i)\n",
    "        if i[1] == object_id:\n",
    "            tracklet.append(i[2:6])\n",
    "    return np.array(tracklet)\n",
    "\n",
    "def tokenizer_frames(tracking, sliding_window):\n",
    "    \n",
    "    token  = [] \n",
    "    for i in range(sliding_window):\n",
    "        current_bbox = tracking[i]\n",
    "        # print(\"bounding box at {} frame : {}\".format(i,current_bbox))\n",
    "        # print(\"tracklet at Nth place is : \", tracking[sliding_window])\n",
    "        delta = np.subtract(tracking[sliding_window], current_bbox)\n",
    "        # print(\"delta is : \", delta)\n",
    "        token.append(delta)\n",
    "    \n",
    "    return np.array(token)\n",
    "\n",
    "\n",
    "for sequence in os.listdir(mot_dir):\n",
    "    # seq = os.path.join(mot_dir, sequence)\n",
    "    image_dir = os.path.join(mot_dir, sequence, \"img1\")\n",
    "    gt_file = os.path.join(mot_dir, sequence, \"gt\", \"gt.txt\")\n",
    "    # print(gt_file)\n",
    "\n",
    "    gt_in = np.loadtxt(gt_file, delimiter = \",\")\n",
    "\n",
    "    # print(gt_in)\n",
    "\n",
    "    ## Lets define 1 tracklet first\n",
    "    object_id = 2 ## Tracklet with Object ID = 1\n",
    "    tracklet = get_tracklet(gt_in, object_id)\n",
    "    # print(\" tracklet is : \", gt_in[tracklet])\n",
    "    print(tracklet.shape)\n",
    "\n",
    "    sliding_window = 50\n",
    "    token = tokenizer_frames(tracklet, sliding_window)\n",
    "\n",
    "\n",
    "    print(\"token shape is : \", token.shape)\n",
    "    token = torch.tensor(token, dtype = torch.float32)\n",
    "\n",
    "    input_dim = 4\n",
    "    output_dim = 4\n",
    "    embedding_layer = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    embedded_tensor = embedding_layer(token)\n",
    "\n",
    "    print(embedded_tensor)\n",
    "\n",
    "    print(\" shape of embedded tensot  : \", embedded_tensor.shape)\n",
    "    \n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from mamba_ssm import Mamba\n",
    "\n",
    "class BiMambaEncoder(nn.Module):\n",
    "    def __init__(self, d_model, n_state):\n",
    "        super(BiMambaEncoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.mamba = Mamba(d_model, n_state)\n",
    "\n",
    "        # Norm and feed-forward network layer\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_model * 4, d_model)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Residual connection of the original input\n",
    "        residual = x\n",
    "        \n",
    "        # Forward Mamba\n",
    "        x_norm = self.norm1(x)\n",
    "        mamba_out_forward = self.mamba(x_norm)\n",
    "\n",
    "        # Backward Mamba\n",
    "        x_flip = torch.flip(x_norm, dims=[1])  # Flip Sequence\n",
    "        mamba_out_backward = self.mamba(x_flip)\n",
    "        mamba_out_backward = torch.flip(mamba_out_backward, dims=[1])  # Flip back\n",
    "\n",
    "        # Combining forward and backward\n",
    "        mamba_out = mamba_out_forward + mamba_out_backward\n",
    "        \n",
    "        mamba_out = self.norm2(mamba_out)\n",
    "        ff_out = self.feed_forward(mamba_out)\n",
    "\n",
    "        output = ff_out + residual\n",
    "        return output\n",
    "\n",
    "# Initialize and test the model\n",
    "d_model = 4\n",
    "n_state = 64\n",
    "model = BiMambaEncoder(d_model, n_state).cuda()\n",
    "x = torch.rand(1, 50, d_model).cuda()  # Analog input data: (batch_size, seq_len, feature_dim)\n",
    "output = model(x)\n",
    "print(output.shape)  # Mamba Out: (32, 100, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Tracklets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_tracklets(data):\n",
    "    first_frame = int(np.min(data[:, 0]))\n",
    "    first_frame_data = data[data[:, 0] == first_frame]\n",
    "    # print(\" first frame data : \", first_frame_data)\n",
    "\n",
    "    tracklets = {}\n",
    "    for row in first_frame_data:\n",
    "        # print(\" row is :\", row)\n",
    "        object_id = int(row[1])\n",
    "        if object_id not in tracklets:\n",
    "            tracklets[object_id] = [row[2:6]]\n",
    "    return tracklets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update tracklets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_tracklets_for_frame(data, tracklets, frame):\n",
    "    # unique_frames = np.unique(data[:, 0])\n",
    "\n",
    "\n",
    "    # for frame in unique_frames:\n",
    "    #     if frame == np.min(data[:, 0]):\n",
    "    #         continue\n",
    "    \n",
    "\n",
    "\n",
    "    frame_data = data[data[:, 0] == frame]\n",
    "\n",
    "    for row in frame_data:\n",
    "        object_id = int(row[1])\n",
    "        if object_id in tracklets:\n",
    "            tracklets[object_id].append(row[2:6])\n",
    "        else:\n",
    "            ## Initialize a new tracklet if the object ID does not exist\n",
    "            tracklets[object_id] = [row[2:6]]\n",
    "\n",
    "    return tracklets\n",
    "### Convert tracklet to numpy arrays\n",
    "\n",
    "def convert_tracklets_to_numpy(tracklets):\n",
    "    for object_id , tracklet_data in tracklets.items():\n",
    "        tracklets[object_id] = np.array(tracklet_data)\n",
    "    \n",
    "    return tracklets\n",
    "\n",
    "\n",
    "\n",
    "def load_data(filename):\n",
    "    data = np.loadtxt(filename, delimiter=',', dtype=float)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"MOT17/train/MOT17-02-SDP/gt/gt.txt\"\n",
    "data = load_data(filename)\n",
    "tracklets = initialize_tracklets(data)\n",
    "\n",
    "unique_frames = np.unique(data[:, 0])\n",
    "for frame in unique_frames:\n",
    "    if frame == 1:\n",
    "        continue\n",
    "    else:\n",
    "        tracklets = update_tracklets_for_frame(data, tracklets, frame)\n",
    "    # trackletsupdate_tracklets(data, tracklets) ## Updates all the tracklets at once. Can be changed to sending data per frame and updating the tracklets in a better way\n",
    "tracklets = convert_tracklets_to_numpy(tracklets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracklets.get(2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracklet Delta - Creating a Tokenizer function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 4)\n"
     ]
    }
   ],
   "source": [
    "def compute_deltas(tracklet_data):\n",
    "    # Compute deltas as described\n",
    "    deltas = []\n",
    "    for i in range(len(tracklet_data) - 1):\n",
    "        delta = tracklet_data[i+1] - tracklet_data[i]\n",
    "        deltas.append(delta)\n",
    "    return np.array(deltas)\n",
    "\n",
    "\n",
    "# Example tracklet data: shape (num_frames, 4) with columns [cx, cy, w, h]\n",
    "# tracklet_data = np.array([\n",
    "#     [100, 150, 50, 60],\n",
    "#     [105, 155, 50, 60],\n",
    "#     [110, 160, 50, 60]\n",
    "# ])\n",
    "\n",
    "\n",
    "# Create delta values for input sequence\n",
    "\n",
    "window_size = 50\n",
    "tracklet_data = tracklets.get(3)[:window_size+1]\n",
    "\n",
    "tracklet_deltas = compute_deltas(tracklet_data)\n",
    "print(tracklet_deltas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Parameters\n",
    "input_dim = tracklet_deltas.shape[1]  # Number of features in deltas (e.g., 4)\n",
    "print(input_dim)\n",
    "# Create and apply embedding layer\n",
    "# embedding_layer = TemporalTokenEmbedding(input_dim, embedding_dim)\n",
    "tracklet_delta_tensor = torch.tensor(tracklet_deltas, dtype=torch.float32).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to implement Bi-Mamba Encdoding Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Forward and Backward Mamba Modules: \n",
    "Implement the forward and backward Mamba modules.\n",
    "#### Create a Bi-Mamba Block: \n",
    "Use the forward and backward modules to process input and apply normalization and MLP.\n",
    "#### Assemble the Bi-Mamba Encoding Layer: \n",
    "Stack multiple Bi-Mamba blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from mamba_ssm import Mamba\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Example usage\n",
    "input_dim = tracklet_delta_tensor.shape[1]  # Number of features in deltas (e.g., 4)\n",
    "embedding_dim = 128 # Example embedding dimension\n",
    "num_blocks = 4  # Number of Bi-Mamba blocks\n",
    "prediction_dim = 4  # Number of predicted offsets\n",
    "\n",
    "# Create and apply model\n",
    "# model = FullModel(input_dim, embedding_dim, num_blocks, prediction_dim).cuda()\n",
    "# predictions = model(tracklet_delta_tensor).cuda()\n",
    "# print(\" shape of predictions : \", predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset class creation -0 copying DIffMOT Class for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = 'MOT17/trackers_gt/train'\n",
    "\n",
    "# interval = 50\n",
    "# train_dataset = MambaMOTDataset(data_path, 50)\n",
    "\n",
    "# train_data_loader = torch.utils.data.DataLoader(\n",
    "#             train_dataset,\n",
    "#             batch_size=64,\n",
    "#             shuffle=True,\n",
    "#             num_workers= 2,\n",
    "#             pin_memory=True\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in train_data_loader:\n",
    "#     # print(\" shape of batch is : \", batch)\n",
    "#     data = batch\n",
    "#     current_gt = data['cur_gt']\n",
    "#     current_bbox = data['cur_bbox']\n",
    "#     delta_bbox = data['delta_bbox']\n",
    "#     print(\"current GT shape :\", current_gt.shape)\n",
    "#     print(\"delta shape : \", delta_bbox.shape)\n",
    "#     print(\"current bbox shape : \", current_bbox.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to create the Dataset class for it to function properly with Mamba/LSTM like model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The previous class was giving me the input tracklets for 10 frames and the target tracklet for 11th frame. Now this class below is going to give me offset format the way it is in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dataset[0] :  (tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], dtype=torch.float64), tensor([0., 0., 0., 0.], dtype=torch.float64))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import sys\n",
    "# sys.path.append('/home/dheerajk/Research_DK/Mamba-MOT')\n",
    "\n",
    "from datasets import MOT20DatasetOffset\n",
    "from torch.utils.data import DataLoader\n",
    "# Initialize the dataset\n",
    "dataset = MOT20DatasetOffset(path='MOT17/train', window_size=11)\n",
    "print(\" dataset[0] : \", dataset[0])\n",
    "# Create a DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Iterate through the DataLoader\n",
    "# for data, targets in dataloader:\n",
    "#     # Your training code here\n",
    "#     print(\"data shape is : \", data.shape)\n",
    "#     print(\"targets shape is : \", targets.shape )\n",
    "\n",
    "    \n",
    "    # pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model parameters\n",
    "input_size = 4  # Bounding box has 4 coordinates: [x, y, width, height]\n",
    "hidden_size = 64 ## This one is used for LSTM NEtwork which I tried\n",
    "output_size = 4  # Output also has 4 coordinates\n",
    "num_layers = 1 ## For LSTM\n",
    "embedding_dim = 128 ## For Mamba\n",
    "num_blocks = 1 ## For Mamba\n",
    "num_epochs = 20\n",
    "\n",
    "warmup_steps = 4000 ## This is for custom warmuo schedular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.SmoothL1Loss()  # Mean squared error loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas = (0.9, 0.98), )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dataloader length is : 9236\n",
      "Accumulated loss is :  2.3095174357149517\n",
      "Epoch [1/100], Loss: 0.0002500560237889727 , Time Taken : 44.247742652893066\n",
      "Accumulated loss is :  2.309519380243728\n",
      "Epoch [2/100], Loss: 0.0002500562343269519 , Time Taken : 44.23379588127136\n",
      "Accumulated loss is :  2.3095168538420694\n",
      "Epoch [3/100], Loss: 0.0002500559607884441 , Time Taken : 43.9530029296875\n",
      "Accumulated loss is :  2.3095174262998626\n",
      "Epoch [4/100], Loss: 0.00025005602276958235 , Time Taken : 44.157885789871216\n",
      "Accumulated loss is :  2.3095159332006006\n",
      "Epoch [5/100], Loss: 0.00025005586110877007 , Time Taken : 44.57202625274658\n"
     ]
    }
   ],
   "source": [
    "from warmup_scheduler_pytorch import WarmUpScheduler\n",
    "from torch.optim.lr_scheduler import StepLR  # example\n",
    "from models_mamba import FullModel, BBoxLSTMModel\n",
    "from schedulars import CustomWarmupScheduler\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# Initialize model\n",
    "\n",
    "# Load data\n",
    "\n",
    "model_used = \"Mamba\" ## LSTM\n",
    "\n",
    "if model_used == \"Mamba\":\n",
    "    model = FullModel(input_size, embedding_dim, num_blocks, output_size).to(device)\n",
    "elif model_used == \"LSTM\":\n",
    "    model = BBoxLSTMModel(input_size, hidden_size, output_size, num_layers).to(device)\n",
    "\n",
    "    \n",
    "dataset = MOT20DatasetOffset(path='MOT17/train', window_size=10)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "scheduler = CustomWarmupScheduler(optimizer, d_model = embedding_dim, warmup_steps = warmup_steps)\n",
    "\n",
    "\n",
    "# scheduler_after_warmup = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "# warmup_scheduler = WarmupScheduler(optimizer, warmup_steps=4000, initial_lr=0.001, warmup_lr=1e-6)\n",
    "\n",
    "import time\n",
    "print(\" dataloader length is :\", len(dataloader))\n",
    "# exit(0)\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "print(\" Model used to training: \", model_used) ## This is just a sanity printing check so that I dont have to see which loss came from which model later on or re-train it\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    epoch_loss = 0.0  # Initialize epoch_loss\n",
    "\n",
    "    for inputs, targets in dataloader:\n",
    "        # Move tensors to the configured device\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        # print(\"shape of inputs is : \", inputs.shape)\n",
    "        targets = targets.float()\n",
    "        # Forward pass\n",
    "        outputs = model(inputs.float())\n",
    "        \n",
    "        # print(\" shape of outputs is : \", outputs.shape)\n",
    "        # print(\" shape of targets is : \", targets.shape)\n",
    "        loss = criterion(outputs, targets)\n",
    "        epoch_loss += loss.item()  # Accumulate loss\n",
    "        # print(\" loss is :\", loss.item())\n",
    "\n",
    "        # print(\"output is : \", outputs)\n",
    "        # print(\"target is : \", targets)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Step the warmup scheduler\n",
    "        # if warmup_scheduler.current_step < warmup_scheduler.warmup_steps:\n",
    "        #     warmup_scheduler.step()\n",
    "        # else:\n",
    "        #     # Step the standard scheduler after warmup\n",
    "        #     scheduler_after_warmup.step()\n",
    "        \n",
    "        # Update the learning rate\n",
    "        scheduler.step()\n",
    "        \n",
    "        \n",
    "    print(\"Accumulated loss is : \", epoch_loss)\n",
    "    avg_loss = epoch_loss / len(dataloader)  # Calculate average loss for the epoch\n",
    "\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "    print('Epoch [{}/{}], Loss: {} , Time Taken : {}'.format(epoch+1, num_epochs, avg_loss, time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4, 29, 49, 10],\n",
       "       [41, 27, 48,  4],\n",
       "       [30, 39, 23, 11],\n",
       "       [ 4,  8, 15, 19],\n",
       "       [ 0, 12, 32, 44],\n",
       "       [15, 17, 18, 35],\n",
       "       [38, 12, 39, 15],\n",
       "       [ 2, 19, 47, 41],\n",
       "       [18, 41, 28, 35],\n",
       "       [41, 35,  0, 31],\n",
       "       [20, 42, 49, 26],\n",
       "       [17, 16, 28, 39]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes = np.random.randint(50, size = (12, 4))\n",
    "bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " i is :  0\n",
      " i is :  1\n",
      " i is :  2\n",
      " i is :  3\n",
      " i is :  4\n",
      " i is :  5\n",
      " i is :  6\n",
      " i is :  7\n",
      "(8, 3, 4)\n",
      " input is :  [[ 37  -2  -1  -6]\n",
      " [-11  12 -25   7]\n",
      " [-26 -31  -8   8]]\n",
      " input is :  [[-11  12 -25   7]\n",
      " [-26 -31  -8   8]\n",
      " [ -4   4  17  25]]\n",
      " input is :  [[-26 -31  -8   8]\n",
      " [ -4   4  17  25]\n",
      " [ 15   5 -14  -9]]\n",
      " input is :  [[ -4   4  17  25]\n",
      " [ 15   5 -14  -9]\n",
      " [ 23  -5  21 -20]]\n",
      " input is :  [[ 15   5 -14  -9]\n",
      " [ 23  -5  21 -20]\n",
      " [-36   7   8  26]]\n",
      " input is :  [[ 23  -5  21 -20]\n",
      " [-36   7   8  26]\n",
      " [ 16  22 -19  -6]]\n",
      " input is :  [[-36   7   8  26]\n",
      " [ 16  22 -19  -6]\n",
      " [ 23  -6 -28  -4]]\n",
      " input is :  [[ 16  22 -19  -6]\n",
      " [ 23  -6 -28  -4]\n",
      " [-21   7  49  -5]]\n",
      "target data is :  [array([-4,  4, 17, 25]), array([ 15,   5, -14,  -9]), array([ 23,  -5,  21, -20]), array([-36,   7,   8,  26]), array([ 16,  22, -19,  -6]), array([ 23,  -6, -28,  -4]), array([-21,   7,  49,  -5]), array([ -3, -26, -21,  13])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "window_size = 4\n",
    "data = []\n",
    "hello = []\n",
    "\n",
    "for i in range(len(bboxes) - window_size):\n",
    "    print(' i is : ', i)\n",
    "    input_diffs = np.diff(bboxes[i:i + window_size + 1], axis=0)\n",
    "    # print(\" input difference are :\", input_diffs)\n",
    "    input_data = input_diffs[:-1]  # Differences for the input window\n",
    "    target_data = input_diffs[-1]  # Difference for the target frame\n",
    "    # print(\" target data is : \", target_data)\n",
    "    data.append(input_data)\n",
    "    hello.append(target_data)\n",
    "\n",
    "\n",
    "# print(bboxes)\n",
    "\n",
    "print(np.shape(data))\n",
    "for i in range(len(data)):\n",
    "    print(\" input is : \", data[i])\n",
    "    \n",
    "    \n",
    "# for j in range(len(hello)):\n",
    "    \n",
    "print(\"target data is : \", hello)\n",
    "\n",
    "# print(\" input data is : \", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mamba_fetrack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
